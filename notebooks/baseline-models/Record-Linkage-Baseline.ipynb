{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Linkage Baseline with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entity_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import tempfile\n",
    "\n",
    "dataset_url = 'https://dbs.uni-leipzig.de/file/Amazon-GoogleProducts.zip'\n",
    "tf = tempfile.NamedTemporaryFile(mode='r', delete=False)\n",
    "tf.close()\n",
    "\n",
    "urllib.request.urlretrieve(dataset_url, tf.name);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amazon.csv', 'GoogleProducts.csv', 'Amzon_GoogleProducts_perfectMapping.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "td = tempfile.TemporaryDirectory()\n",
    "\n",
    "with zipfile.ZipFile(tf.name, \"r\") as zf:\n",
    "    zf.extractall(td.name)\n",
    "\n",
    "os.listdir(td.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from entity_embed.data_utils.utils import Enumerator\n",
    "\n",
    "id_enumerator = Enumerator()\n",
    "record_dict = {}\n",
    "source_field = '__source'\n",
    "left_source = 'amazon'\n",
    "right_source = 'google'\n",
    "\n",
    "with open(f'{td.name}/Amazon.csv', newline='', encoding=\"latin1\") as f:\n",
    "    for record in csv.DictReader(f):\n",
    "        record['id'] = id_enumerator[record[\"id\"]]\n",
    "        record['name'] = record.pop('title')  # in Amazon, name is called title\n",
    "        record[source_field] = left_source\n",
    "        record_dict[record['id']] = record\n",
    "\n",
    "with open(f'{td.name}/GoogleProducts.csv', newline='', encoding=\"latin1\") as f:\n",
    "    for record in csv.DictReader(f):\n",
    "        record['id'] = id_enumerator[record[\"id\"]]\n",
    "        record[source_field] = right_source\n",
    "        record_dict[record['id']] = record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_pair_set = set()\n",
    "\n",
    "with open(f'{td.name}/Amzon_GoogleProducts_perfectMapping.csv', newline='') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        id_left = id_enumerator[row['idAmazon']]\n",
    "        id_right = id_enumerator[row['idGoogleBase']]\n",
    "        pos_pair_set.add((id_left, id_right))\n",
    "\n",
    "len(pos_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3290"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.data_utils import utils\n",
    "\n",
    "cluster_mapping, cluster_dict = utils.id_pairs_to_cluster_mapping_and_dict(pos_pair_set, record_dict)\n",
    "len(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[262, 2485, 2488]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_dict[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 4]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cluster_mapping[id_] for id_ in cluster_dict[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 262,\n",
       " 'description': 'sp linux we 50 lic/cd 3.0c',\n",
       " 'manufacturer': 'hewlett packard (consumables)',\n",
       " 'price': '0',\n",
       " 'name': 'hp sp linux we 50 lic/cd 3.0c ( t3586a )',\n",
       " '__source': 'amazon',\n",
       " 'cluster': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 2485,\n",
       " 'name': 'sp linux we 50 lic/cd 3.0c',\n",
       " 'description': '',\n",
       " 'manufacturer': '',\n",
       " 'price': '69216.95',\n",
       " '__source': 'google',\n",
       " 'cluster': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'id': 2488,\n",
       " 'name': 'sp linux we 50 lic/cd 3.0c',\n",
       " 'description': '',\n",
       " 'manufacturer': '',\n",
       " 'price': '69216.95',\n",
       " '__source': 'google',\n",
       " 'cluster': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_field = 'cluster'\n",
    "utils.assign_clusters(record_dict, cluster_field, cluster_mapping)\n",
    "\n",
    "for id_ in cluster_dict[4]:\n",
    "    display(record_dict[id_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.data_utils.utils import cluster_dict_to_id_pairs\n",
    "\n",
    "len(cluster_dict_to_id_pairs(cluster_dict) - pos_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:05:26 INFO:Singleton cluster sizes (train, valid, test):(437, 437, 1311)\n",
      "10:05:26 INFO:Plural cluster sizes (train, valid, test):(221, 221, 663)\n"
     ]
    }
   ],
   "source": [
    "from entity_embed.data_utils import utils\n",
    "\n",
    "train_record_dict, valid_record_dict, test_record_dict = utils.split_record_dict_on_clusters(\n",
    "    record_dict=record_dict,\n",
    "    cluster_field=cluster_field,\n",
    "    train_proportion=0.2,\n",
    "    valid_proportion=0.2,\n",
    "    random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(926, 912, 2751)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_record_dict), len(valid_record_dict), len(test_record_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "td.cleanup()\n",
    "os.remove(tf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list = ['name', 'description', 'manufacturer', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import itertools\n",
    "from entity_embed import default_tokenizer\n",
    "\n",
    "def clean_str(s):\n",
    "    max_tokens = 100\n",
    "    max_chars = 1000\n",
    "    s = unidecode.unidecode(s).lower().strip()\n",
    "    s_tokens = default_tokenizer(s)[:max_tokens]\n",
    "    return ' '.join(s_tokens)[:max_chars]\n",
    "\n",
    "for record in record_dict.values():\n",
    "    for field in field_list:\n",
    "        record[field] = clean_str(record[field])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True positive pair sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_id_set, right_id_set = utils.record_dict_to_left_right_id_set(\n",
    "    record_dict=record_dict,\n",
    "    source_field=source_field,\n",
    "    left_source=left_source,\n",
    ")\n",
    "train_cluster_dict = utils.record_dict_to_cluster_dict(\n",
    "    train_record_dict, cluster_field\n",
    ")\n",
    "valid_cluster_dict = utils.record_dict_to_cluster_dict(\n",
    "    valid_record_dict, cluster_field\n",
    ")\n",
    "test_cluster_dict = utils.record_dict_to_cluster_dict(\n",
    "    test_record_dict, cluster_field\n",
    ")\n",
    "\n",
    "train_pos_pair_set = utils.cluster_dict_to_id_pairs(\n",
    "    train_cluster_dict,\n",
    "    left_id_set=left_id_set,\n",
    "    right_id_set=right_id_set\n",
    ")\n",
    "valid_pos_pair_set = utils.cluster_dict_to_id_pairs(\n",
    "    valid_cluster_dict,\n",
    "    left_id_set=left_id_set,\n",
    "    right_id_set=right_id_set\n",
    ")\n",
    "test_pos_pair_set = utils.cluster_dict_to_id_pairs(\n",
    "    test_cluster_dict,\n",
    "    left_id_set=left_id_set,\n",
    "    right_id_set=right_id_set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1363, 3226)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(left_id_set), len(right_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 254, 778)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pos_pair_set), len(valid_pos_pair_set), len(test_pos_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hp sp linux we 50 lic / cd 3 . 0c ( t3586a ) sp linux we 50 lic / cd 3 . 0c hewlett packard ( consumables ) 0'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_name_dict = {id_: \" \".join(record[f] for f in field_list) for id_, record in train_record_dict.items()}\n",
    "valid_name_dict = {id_: \" \".join(record[f] for f in field_list) for id_, record in valid_record_dict.items()}\n",
    "test_name_dict = {id_: \" \".join(record[f] for f in field_list) for id_, record in test_record_dict.items()}\n",
    "\n",
    "train_name_dict[262]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    analyzer='char',\n",
    "    ngram_range=(2,4),\n",
    "    min_df=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1838x29779 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1094687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf_matrix = tfidf_vectorizer.fit_transform(\n",
    "    itertools.chain(train_name_dict.values(), valid_name_dict.values()))\n",
    "train_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2751x29779 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1609033 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tfidf_matrix = tfidf_vectorizer.transform(test_name_dict.values())\n",
    "test_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 40s, sys: 49.5 s, total: 3min 30s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pynndescent\n",
    "\n",
    "index = pynndescent.NNDescent(test_tfidf_matrix, random_state=random_seed, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,  829, 1418, ..., 1729, 2529, 1782],\n",
       "        [   1,   21,  125, ...,   34, 2747, 1569],\n",
       "        [   2,  875, 1467, ...,  183,  576, 1473],\n",
       "        ...,\n",
       "        [2748, 1766, 2747, ..., 1581, 1527, 2485],\n",
       "        [2749, 1131, 2750, ..., 1621, 2295, 2337],\n",
       "        [2750, 2228, 2268, ..., 1292, 1817, 2432]]),\n",
       " array([[0.00000000e+00, 3.00228744e-01, 3.51883112e-01, ...,\n",
       "         8.80558527e-01, 8.81367141e-01, 8.83136569e-01],\n",
       "        [3.57627751e-07, 6.52536948e-01, 6.64479614e-01, ...,\n",
       "         7.41805508e-01, 7.42226777e-01, 7.43839719e-01],\n",
       "        [1.19209271e-07, 6.36853172e-01, 7.35978994e-01, ...,\n",
       "         8.84838734e-01, 8.85170582e-01, 8.85556467e-01],\n",
       "        ...,\n",
       "        [2.38418528e-07, 5.37369222e-02, 2.16594446e-01, ...,\n",
       "         7.66124577e-01, 7.67505854e-01, 7.68192396e-01],\n",
       "        [0.00000000e+00, 6.06169811e-01, 6.34850939e-01, ...,\n",
       "         8.81643174e-01, 8.82741866e-01, 8.83194879e-01],\n",
       "        [0.00000000e+00, 2.94851373e-01, 4.22057558e-01, ...,\n",
       "         7.67956182e-01, 7.68083384e-01, 7.70027419e-01]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.neighbor_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26644"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_threshold = 0.3\n",
    "\n",
    "found_neighbors, found_distances = index.neighbor_graph\n",
    "found_sims = 1 - found_distances\n",
    "found_pair_set = set()\n",
    "test_ids = list(test_name_dict.keys())\n",
    "\n",
    "for left_id, neighbors, sims in zip(test_ids, found_neighbors.tolist(), found_sims.tolist()):\n",
    "    for right_i, sim in zip(neighbors, sims):\n",
    "        right_id = test_ids[right_i]\n",
    "        \n",
    "        if left_id == right_id:\n",
    "            continue\n",
    "        if sim >= sim_threshold:\n",
    "            if left_id in left_id_set:\n",
    "                found_pair = (left_id, right_id)\n",
    "            else:\n",
    "                found_pair = (right_id, left_id)\n",
    "            found_pair_set.add(found_pair)\n",
    "            \n",
    "len(found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.685205379861868"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.evaluation import pair_entity_ratio\n",
    "\n",
    "pair_entity_ratio(len(found_pair_set), len(test_record_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.023044587899714756, 0.7892030848329049)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.evaluation import precision_and_recall\n",
    "\n",
    "precision_and_recall(found_pair_set, test_pos_pair_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
