{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14315d5a",
   "metadata": {},
   "source": [
    "# End to End Matching Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3080847d",
   "metadata": {},
   "source": [
    "Before running this notebook on Google Colab, please make sure to set the runtime type to \"GPU\". Do that by going to the \"Runtime\" menu and selecting \"Change runtime type\".\n",
    "\n",
    "Also, please run [Record-Linkage-Example.ipynb](https://colab.research.google.com/github/vintasoftware/entity-embed/blob/google-collab-notebooks/notebooks/google-colab/Record-Linkage-Example.ipynb) before this one in order to get the trained model and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae51fb",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6be39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install entity-embed\n",
    "!pip install \"matplotlib==3.1.1\" \\\n",
    "             \"pynndescent==0.5.2\" \\\n",
    "             \"scikit-learn==0.24.1\" \\\n",
    "             \"seaborn==0.11.1\" \\\n",
    "             \"unidecode==1.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41394338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e239b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdf412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import entity_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d581925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81e6680",
   "metadata": {},
   "source": [
    "## Loading Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-canyon",
   "metadata": {},
   "source": [
    "We'll use Google Drive to read the Record Linkage output files, please make sure to authorize Google Colab to use your Google Drive account once the cell below runs. Also, please ensure that all files exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "rl_output_path = \"/content/drive/My Drive/trained-models/notebooks/rl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105a7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ordered_set import OrderedSet\n",
    "\n",
    "def load_pair_set(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        test_pos_pair_set = json.load(f)\n",
    "        return OrderedSet(tuple(pair) for pair in test_pos_pair_set)\n",
    "\n",
    "train_pos_pair_set = load_pair_set(f'{rl_output_path}/rl-train-pos-pairs.json')\n",
    "valid_pos_pair_set = load_pair_set(f'{rl_output_path}/rl-valid-pos-pairs.json')\n",
    "test_pos_pair_set = load_pair_set(f'{rl_output_path}/rl-test-pos-pairs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af3fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def load_record_dict(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        record_dict = json.load(f)\n",
    "        return {int(id_): record for id_, record in record_dict.items()}\n",
    "\n",
    "train_record_dict = load_record_dict(f'{rl_output_path}/rl-train-records.json')\n",
    "valid_record_dict = load_record_dict(f'{rl_output_path}/rl-valid-records.json')\n",
    "test_record_dict = load_record_dict(f'{rl_output_path}/rl-test-records.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e691355",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed import LinkageEmbed\n",
    "\n",
    "model = LinkageEmbed.load_from_checkpoint(f'{rl_output_path}/rl-model.ckpt')\n",
    "model = model.to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1861a",
   "metadata": {},
   "source": [
    "## Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9287762",
   "metadata": {},
   "source": [
    "Use `sim_threshold = 0.375` to have ~6k pairs in `train_found_pair_set` and have a fair comparison with [baseline-models/End-to-End-Matching-Baseline.ipynb](./baseline-models/End-to-End-Matching-Baseline.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a07f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "eval_batch_size = 64\n",
    "ann_k = 100\n",
    "sim_threshold = 0.375\n",
    "\n",
    "train_found_pair_set, train_left_field_vector_dict, train_right_field_vector_dict = model.predict_pairs(\n",
    "    record_dict=train_record_dict,\n",
    "    batch_size=eval_batch_size,\n",
    "    ann_k=ann_k,\n",
    "    sim_threshold=sim_threshold,\n",
    "    show_progress=True,\n",
    "    return_field_embeddings=True\n",
    ")\n",
    "len(train_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2739357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_found_pair_set, valid_left_field_vector_dict, valid_right_field_vector_dict = model.predict_pairs(\n",
    "    record_dict=valid_record_dict,\n",
    "    batch_size=eval_batch_size,\n",
    "    ann_k=ann_k,\n",
    "    sim_threshold=sim_threshold,\n",
    "    show_progress=True,\n",
    "    return_field_embeddings=True\n",
    ")\n",
    "len(valid_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d16e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_found_pair_set, test_left_field_vector_dict, test_right_field_vector_dict = model.predict_pairs(\n",
    "    record_dict=test_record_dict,\n",
    "    batch_size=eval_batch_size,\n",
    "    ann_k=ann_k,\n",
    "    sim_threshold=sim_threshold,\n",
    "    show_progress=True,\n",
    "    return_field_embeddings=True\n",
    ")\n",
    "len(test_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69257b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_attn_scores_dict = model.interpret_attention(\n",
    "    record_dict=test_record_dict,\n",
    "    batch_size=eval_batch_size,\n",
    "    field='title',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b09386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import pair_entity_ratio\n",
    "\n",
    "pair_entity_ratio(len(test_found_pair_set), len(test_record_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9d6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import precision_and_recall\n",
    "\n",
    "precision_and_recall(test_found_pair_set, test_pos_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb67907",
   "metadata": {},
   "source": [
    "Complement the train/valid `found_pair_set` with `pos_pair_set` for training.  \n",
    "Leave test untoched, to reproduce production behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6cd20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_found_pair_set |= train_pos_pair_set\n",
    "valid_found_pair_set |= valid_pos_pair_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6925ac",
   "metadata": {},
   "source": [
    "## Matching: Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d29e62",
   "metadata": {},
   "source": [
    "Make a dataframe `df` with all records (train, valid, test) to add additional features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14577317",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dict = {**train_record_dict, **valid_record_dict, **test_record_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03d21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(record_dict, orient='index')\n",
    "df = df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3e72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all'] = df.agg('{0[title]} - {0[manufacturer]} - {0[price]}'.format, axis=1)\n",
    "df['price'] = pd.to_numeric(df['price'].str.replace(' ', ''), errors='coerce')\n",
    "del df['cluster']\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1789693",
   "metadata": {},
   "source": [
    "Replace all `record_dict`s (train, valid, test) to add additional features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1732a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_record_dict = df.loc[train_record_dict.keys()].to_dict(orient='index')\n",
    "valid_record_dict = df.loc[valid_record_dict.keys()].to_dict(orient='index')\n",
    "test_record_dict = df.loc[test_record_dict.keys()].to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance as td\n",
    "import math\n",
    "\n",
    "def exact_eq(x, y):\n",
    "    return float(x == y)\n",
    "\n",
    "def token_ops(func):\n",
    "    def new_func(x, y):\n",
    "        return func(x.split(), y.split())    \n",
    "    return new_func\n",
    "\n",
    "def abs_diff(x, y):\n",
    "    return abs(x - y)\n",
    "\n",
    "def abs_diff_log10(x, y):\n",
    "    diff = abs_diff(x, y)\n",
    "    if diff > 1:\n",
    "        return math.log10(diff)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "SIM_FUNC_DICT = {\n",
    "    (\"all\", \"jaccard\"): token_ops(td.jaccard.normalized_similarity),\n",
    "    (\"all\", \"overlap\"): token_ops(td.overlap.normalized_similarity),\n",
    "    (\"all\", \"damerau_levenshtein\"): td.damerau_levenshtein.normalized_similarity,\n",
    "    (\"all\", \"jaro_winkler\"): td.jaro_winkler.normalized_similarity,\n",
    "    (\"manufacturer\", \"jaccard\"): token_ops(td.jaccard.normalized_similarity),\n",
    "    (\"manufacturer\", \"overlap\"): token_ops(td.overlap.normalized_similarity),\n",
    "    (\"manufacturer\", \"damerau_levenshtein\"): td.damerau_levenshtein.normalized_similarity,\n",
    "    (\"manufacturer\", \"jaro_winkler\"): td.jaro_winkler.normalized_similarity,\n",
    "    (\"title\", \"jaccard\"): token_ops(td.jaccard.normalized_similarity),\n",
    "    (\"title\", \"overlap\"): token_ops(td.overlap.normalized_similarity),\n",
    "    (\"title\", \"damerau_levenshtein\"): td.damerau_levenshtein.normalized_similarity,\n",
    "    (\"title\", \"jaro_winkler\"): td.jaro_winkler.normalized_similarity,\n",
    "    (\"price\", \"abs_diff\"): abs_diff,\n",
    "    (\"price\", \"abs_diff_log10\"): abs_diff_log10,\n",
    "}\n",
    "\n",
    "def record_sim_func(record_pair):\n",
    "    record_left, record_right = record_pair\n",
    "    feature_dict = {}\n",
    "    \n",
    "    for (field, sim_func_name), sim_func in SIM_FUNC_DICT.items():\n",
    "        x = record_left[field]\n",
    "        y = record_right[field]\n",
    "        if x and y:\n",
    "            if sim_func_name.startswith('abs_diff') and (math.isnan(x) or math.isnan(y)):\n",
    "                sim = -1.0\n",
    "            else:\n",
    "                sim = sim_func(x, y)\n",
    "        else:\n",
    "            sim = -1.0\n",
    "        feature_dict[f\"{field}_{sim_func_name}\"] = sim\n",
    "    \n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9789cd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pair = next(iter(test_pos_pair_set))\n",
    "id_left, id_right = pair\n",
    "feature_dict = record_sim_func((test_record_dict[id_left], test_record_dict[id_right]))\n",
    "\n",
    "# display(test_record_dict[id_left], test_record_dict[id_right])\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad8dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def compare_pairs(record_dict, found_pair_set):\n",
    "    all_feature_dict = defaultdict(list)\n",
    "    chunksize = 100\n",
    "    tasks = (\n",
    "        (record_dict[id_left], record_dict[id_right])\n",
    "        for (id_left, id_right)\n",
    "        in found_pair_set\n",
    "    )\n",
    "\n",
    "    with multiprocessing.Pool() as pool:\n",
    "        for feature_dict in tqdm(\n",
    "            pool.imap(record_sim_func, tasks, chunksize=chunksize),\n",
    "            total=len(found_pair_set)\n",
    "        ):\n",
    "            for feature, val in feature_dict.items():\n",
    "                all_feature_dict[feature].append(val)\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    \n",
    "    return pd.DataFrame(all_feature_dict, index=pd.MultiIndex.from_tuples(found_pair_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73ff3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_feature_df = compare_pairs(train_record_dict, train_found_pair_set)\n",
    "assert len(train_feature_df) == len(train_found_pair_set)\n",
    "len(train_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8bb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "valid_feature_df = compare_pairs(valid_record_dict, valid_found_pair_set)\n",
    "assert len(valid_feature_df) == len(valid_found_pair_set)\n",
    "len(valid_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e8c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_feature_df = compare_pairs(test_record_dict, test_found_pair_set)\n",
    "assert len(test_feature_df) == len(test_found_pair_set)\n",
    "len(test_found_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe58af0",
   "metadata": {},
   "source": [
    "## Matching: Compare - TFIDF Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871df4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_tfidf_vectorizer(train_record_dict, valid_record_dict, field='all'):\n",
    "    tfidf_vectorizer = TfidfVectorizer(\n",
    "        analyzer='char',\n",
    "        ngram_range=(2,4),\n",
    "        min_df=2\n",
    "    )\n",
    "    train_valid_record_dict = {**train_record_dict, **valid_record_dict}\n",
    "    tfidf_vectorizer.fit(record[field] for record in train_valid_record_dict.values())\n",
    "    return tfidf_vectorizer\n",
    "\n",
    "tfidf_vectorizer = get_tfidf_vectorizer(train_record_dict, valid_record_dict)\n",
    "tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef71ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_tfidf_feature(tfidf_vectorizer, feature_df, record_dict, found_pair_set, field='all'):\n",
    "    tfidf_matrix = tfidf_vectorizer.transform(record[field] for record in record_dict.values())\n",
    "\n",
    "    id_to_idx = {id_: idx for idx, id_ in enumerate(record_dict.keys())}\n",
    "    left_idx = [id_to_idx[left_id] for left_id, __ in found_pair_set]\n",
    "    right_idx = [id_to_idx[right_id] for __, right_id in found_pair_set]\n",
    "    tfidf_sim = tfidf_matrix[left_idx].multiply(tfidf_matrix[right_idx]).sum(axis=1)  # cos per row\n",
    "\n",
    "    feature_df[f'{field}_tfidf'] = tfidf_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_tfidf_feature(tfidf_vectorizer, train_feature_df, train_record_dict, train_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfc48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_tfidf_feature(tfidf_vectorizer, valid_feature_df, valid_record_dict, valid_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_tfidf_feature(tfidf_vectorizer, test_feature_df, test_record_dict, test_found_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a02e01",
   "metadata": {},
   "source": [
    "## Matching: Compare - Embedding Cosine Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772f99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def add_embed_cos_features(feature_df, left_field_vector_dict, right_field_vector_dict, found_pair_set):\n",
    "    fields = next(iter(left_field_vector_dict.values())).keys()\n",
    "    \n",
    "    for field in fields:\n",
    "        left_embed = np.stack([left_field_vector_dict[left_id][field] for left_id, __ in found_pair_set])\n",
    "        right_embed = np.stack([right_field_vector_dict[right_id][field] for __, right_id in found_pair_set])\n",
    "        normalize(left_embed, copy=False)\n",
    "        normalize(right_embed, copy=False)\n",
    "        sim = np.multiply(left_embed, right_embed).sum(axis=1)  # cos per row\n",
    "        feature_df[f'embed_{field}_cos'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967964d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_embed_cos_features(\n",
    "    train_feature_df,\n",
    "    train_left_field_vector_dict,\n",
    "    train_right_field_vector_dict,\n",
    "    train_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9549bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_embed_cos_features(\n",
    "    valid_feature_df,\n",
    "    valid_left_field_vector_dict,\n",
    "    valid_right_field_vector_dict,\n",
    "    valid_found_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cccd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "add_embed_cos_features(\n",
    "    test_feature_df,\n",
    "    test_left_field_vector_dict,\n",
    "    test_right_field_vector_dict,\n",
    "    test_found_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd1185e",
   "metadata": {},
   "source": [
    "## Matching: Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f60ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_feature_df = pd.concat([train_feature_df, valid_feature_df])\n",
    "train_valid_feature_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e3eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_true_y = np.array([pair in train_pos_pair_set for pair in train_found_pair_set], dtype='i4')\n",
    "valid_true_y = np.array([pair in valid_pos_pair_set for pair in valid_found_pair_set], dtype='i4')\n",
    "test_true_y = np.array([pair in test_pos_pair_set for pair in test_found_pair_set], dtype='i4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471adca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_true_y = np.concatenate([train_true_y, valid_true_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98c3077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import PredefinedSplit, GridSearchCV\n",
    "\n",
    "cv = PredefinedSplit(\n",
    "    np.concatenate([\n",
    "        np.full(train_true_y.shape[0], -1 ,dtype='i4'),\n",
    "        np.zeros(valid_true_y.shape[0], dtype='i4')\n",
    "    ])\n",
    ")\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 200],\n",
    "    'max_depth': [5, 10, 25, 50, None],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "}\n",
    "clf = RandomForestClassifier(oob_score=True, random_state=random_seed)\n",
    "clf = GridSearchCV(clf, param_grid, scoring='f1', cv=cv, verbose=10, n_jobs=-1)\n",
    "clf.fit(train_valid_feature_df, train_valid_true_y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76241b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5861cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_estimator_.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20dd9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importances = dict(zip(train_valid_feature_df.columns, clf.best_estimator_.feature_importances_))\n",
    "sorted(feature_importances.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde175ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "cls_threshold = 0.3\n",
    "train_valid_pred_y = clf.predict_proba(train_valid_feature_df)\n",
    "train_valid_pred_y[train_valid_pred_y >= cls_threshold] = 1\n",
    "train_valid_pred_y[train_valid_pred_y < cls_threshold] = 0\n",
    "train_valid_pred_y = train_valid_pred_y[:, 1]\n",
    "accuracy_score(train_valid_pred_y, train_valid_true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "prob_y = clf.predict_proba(test_feature_df)\n",
    "pred_y = np.copy(prob_y)\n",
    "pred_y[pred_y >= cls_threshold] = 1\n",
    "pred_y[pred_y < cls_threshold] = 0\n",
    "pred_y = pred_y[:, 1]\n",
    "precision_recall_fscore_support(test_true_y, pred_y, labels=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378f9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_found_pair_set = OrderedSet(test_feature_df[pred_y.astype(bool)].index)\n",
    "\n",
    "precision_and_recall(cls_found_pair_set, test_pos_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137b59d",
   "metadata": {},
   "source": [
    "False negatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df0cb98",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for x, y in list(test_pos_pair_set - cls_found_pair_set)[:5]:\n",
    "    print(clf.predict_proba(test_feature_df.loc[[(x, y)]]))\n",
    "    display(df.loc[[x, y]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcef2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = (725, 1803)\n",
    "display(test_feature_df.loc[[pair]])\n",
    "clf.predict_proba(test_feature_df.loc[[pair]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dde2b4",
   "metadata": {},
   "source": [
    "Hard cases attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fa4c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_df = pd.DataFrame(prob_y[:,1], columns=['prob'], index=test_feature_df.index)\n",
    "hard_prob_df = prob_df.loc[(prob_df['prob'] >= cls_threshold) & (prob_df['prob'] <= cls_threshold + 0.01)]\n",
    "hard_prob_df = hard_prob_df.loc[hard_prob_df.index.intersection(test_pos_pair_set)]\n",
    "hard_prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from entity_embed import default_tokenizer\n",
    "\n",
    "def display_attention(id_, field):\n",
    "    tokens = default_tokenizer(test_record_dict[id_][field])\n",
    "    attn_scores = test_attn_scores_dict[id_][:len(tokens)]\n",
    "    attn_df = pd.DataFrame(dict(zip(tokens, attn_scores)), index=[id_])\n",
    "    cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "    display(attn_df.style.background_gradient(cmap=cm, axis=1))\n",
    "\n",
    "def display_pair_attention(pair, field):\n",
    "    left_id, right_id = pair\n",
    "    display_attention(left_id, field)\n",
    "    display_attention(right_id, field)\n",
    "\n",
    "for pair in hard_prob_df.index:\n",
    "    display_pair_attention(pair, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01227cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "disp = plot_precision_recall_curve(clf, test_feature_df, test_true_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
