{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deduplication Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: entity-embed in /home/renato/Desktop/entity-embed (0.0.2)\n",
      "Requirement already satisfied: click==7.1.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (7.1.2)\n",
      "Requirement already satisfied: more-itertools>=8.6.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (8.6.0)\n",
      "Requirement already satisfied: n2>=0.1.7 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (0.1.7)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (1.19.4)\n",
      "Requirement already satisfied: ordered-set>=4.0.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (4.0.2)\n",
      "Requirement already satisfied: pytorch_lightning>=1.1.6 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (1.1.6)\n",
      "Requirement already satisfied: pytorch-metric-learning>=0.9.98 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (0.9.98)\n",
      "Requirement already satisfied: regex>=2020.11.13 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (2020.11.13)\n",
      "Requirement already satisfied: torch>=1.7.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (1.7.1)\n",
      "Requirement already satisfied: torchtext>=0.8.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (0.8.1)\n",
      "Requirement already satisfied: tqdm>=4.53.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from entity-embed) (4.53.0)\n",
      "Requirement already satisfied: cython in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from n2>=0.1.7->entity-embed) (0.29.21)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch_lightning>=1.1.6->entity-embed) (2.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=0.8.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch_lightning>=1.1.6->entity-embed) (0.8.5)\n",
      "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch_lightning>=1.1.6->entity-embed) (5.3.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch_lightning>=1.1.6->entity-embed) (0.18.2)\n",
      "Requirement already satisfied: requests in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (2.25.1)\n",
      "Requirement already satisfied: aiohttp in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (3.7.3)\n",
      "Requirement already satisfied: scikit-learn in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch-metric-learning>=0.9.98->entity-embed) (0.24.1)\n",
      "Requirement already satisfied: torchvision in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pytorch-metric-learning>=0.9.98->entity-embed) (0.8.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (49.2.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.35.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (0.36.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.24.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (0.4.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (3.14.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (0.11.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (3.3.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (4.7)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from requests->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning>=1.1.6->entity-embed) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from torch>=1.7.1->entity-embed) (3.7.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (20.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (1.6.3)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (3.0.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning>=1.1.6->entity-embed) (5.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy>=0.19.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning>=0.9.98->entity-embed) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning>=0.9.98->entity-embed) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning>=0.9.98->entity-embed) (2.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from torchvision->pytorch-metric-learning>=0.9.98->entity-embed) (8.0.1)\n",
      "Requirement already satisfied: matplotlib==3.4.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (3.4.1)\n",
      "Requirement already satisfied: pynndescent==0.5.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (0.5.2)\n",
      "Requirement already satisfied: scikit-learn==0.24.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (0.24.1)\n",
      "Requirement already satisfied: seaborn==0.11.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: unidecode==1.1.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (1.1.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (1.19.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (8.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from matplotlib==3.4.1) (2.4.7)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pynndescent==0.5.2) (1.5.4)\n",
      "Requirement already satisfied: llvmlite>=0.30 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pynndescent==0.5.2) (0.36.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pynndescent==0.5.2) (0.53.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pynndescent==0.5.2) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from scikit-learn==0.24.1) (2.1.0)\n",
      "Requirement already satisfied: pandas>=0.23 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from seaborn==0.11.1) (1.2.3)\n",
      "Requirement already satisfied: six in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from cycler>=0.10->matplotlib==3.4.1) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from numba>=0.51.2->pynndescent==0.5.2) (49.2.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/renato/Desktop/entity-embed/venv/lib/python3.8/site-packages (from pandas>=0.23->seaborn==0.11.1) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install entity-embed\n",
    "!pip install \"matplotlib==3.4.1\" \\\n",
    "             \"pynndescent==0.5.2\" \\\n",
    "             \"scikit-learn==0.24.1\" \\\n",
    "             \"seaborn==0.11.1\" \\\n",
    "             \"unidecode==1.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import entity_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [Music Brainz 20K from Database Group Leipzig](https://dbs.uni-leipzig.de/research/projects/object_matching/benchmark_datasets_for_entity_resolution). From the site: \"The Music Brainz dataset is based on real records about songs from the MusicBrainz database but uses the DAPO data generator to create duplicates with modified attribute values. The generated dataset consists of five sources and contains duplicates for 50% of the original records in two to five sources. All duplicates are generated with a high degree of corruption to stress-test the ER and clustering approaches.\"\n",
    "\n",
    "Here is it's [README](https://www.informatik.uni-leipzig.de/~saeedi/musicBrainz_readme.txt):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "5 sources\n",
    "---------- \n",
    "TID: a unique record's id (in the complete dataset).\n",
    "CID: cluster id (records having the same CID are duplicate)\n",
    "CTID: a unique id within a cluster (if two records belong to the same cluster they will have the same CID but different CTIDs). These ids (CTID) start with 1 and grow until cluster size.\n",
    "SourceID: identifies to which source a record belongs (there are five sources). The sources are deduplicated.\n",
    "Id: the original id from the source. Each source has its own Id-Format. Uniqueness is not guaranteed!! (can be ignored).\n",
    "number: track or song number in the album.\n",
    "length: the length of the track.\n",
    "artist: the interpreter (artist or band) of the track.\n",
    "year: date of publication.\n",
    "language: language of the track.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the CSV dataset to a temporary directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import tempfile\n",
    "\n",
    "dataset_url = 'https://www.informatik.uni-leipzig.de/~saeedi/musicbrainz-20-A01.csv.dapo'\n",
    "tf = tempfile.NamedTemporaryFile(mode='r', delete=False)\n",
    "tf.close()\n",
    "\n",
    "urllib.request.urlretrieve(dataset_url, tf.name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must read the CSV dataset into a `dict` called `record_dict`.\n",
    "\n",
    "`record_dict` will contain all records from the dataset, and each record will have the indication of the true cluster it belongs to in the field `CID`.\n",
    "\n",
    "So `CID` is our `cluster_field`. Entity Embed needs that to train, validate, and test.\n",
    "\n",
    "We'll dynamically attribute an `id` to each record using `enumerate`. Entity Embed needs that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "record_dict = {}\n",
    "cluster_field = 'CID'\n",
    "\n",
    "with open(tf.name, newline='') as f:\n",
    "    for current_record_id, record in enumerate(csv.DictReader(f)):\n",
    "        record['id'] = current_record_id\n",
    "        record[cluster_field] = int(record[cluster_field])  # convert cluster_field to int\n",
    "        record_dict[current_record_id] = record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TID': '84',\n",
       " 'CID': 9369,\n",
       " 'CTID': '4',\n",
       " 'SourceID': '4',\n",
       " 'id': 83,\n",
       " 'number': '1',\n",
       " 'title': '001-Berimbou',\n",
       " 'length': '2m 23sec',\n",
       " 'artist': 'Astrud Gilberto',\n",
       " 'album': 'Look to the Rainbow (2008)',\n",
       " 'year': 'null',\n",
       " 'language': ' Eng.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_dict[83]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a great song, but it's actually called \"Berimbau\", not \"Berimbou\"! And it's a Brazilian song, in Portuguese. This a small example on how noisy is this dataset..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many clusters this dataset has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_total = len(set(record[cluster_field] for record in record_dict.values()))\n",
    "cluster_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From all clusters, we'll use only 20% for training, and other 20% for validation to test how well we can generalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:02:16 INFO:Singleton cluster sizes (train, valid, test):(1000, 1000, 3000)\n",
      "09:02:16 INFO:Plural cluster sizes (train, valid, test):(1000, 1000, 3000)\n"
     ]
    }
   ],
   "source": [
    "from entity_embed.data_utils import utils\n",
    "\n",
    "train_record_dict, valid_record_dict, test_record_dict = utils.split_record_dict_on_clusters(\n",
    "    record_dict=record_dict,\n",
    "    cluster_field=cluster_field,\n",
    "    train_proportion=0.2,\n",
    "    valid_proportion=0.2,\n",
    "    random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note we're splitting the data on **clusters**, not records, so the record counts vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3845, 3876, 11654)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_record_dict), len(valid_record_dict), len(test_record_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up the temporary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.remove(tf.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll perform a very minimal preprocessing of the dataset. We want to simply force ASCII chars, lowercase all chars, and strip leading and trailing whitespace.\n",
    "\n",
    "The fields we'll clean are the ones we'll use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list = ['number', 'title', 'artist', 'album', 'year', 'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "def clean_str(s):\n",
    "    return unidecode.unidecode(s).lower().strip()\n",
    "\n",
    "for record in record_dict.values():\n",
    "    for field in field_list:\n",
    "        record[field] = clean_str(record[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'number': '1',\n",
       " 'title': '001-berimbou',\n",
       " 'artist': 'astrud gilberto',\n",
       " 'album': 'look to the rainbow (2008)',\n",
       " 'year': 'null',\n",
       " 'language': 'eng.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.subdict(record_dict[83], field_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forcing ASCII chars in this dataset is useful to improve recall because there's little difference between accented and not-accented chars here. Also, this dataset contains mostly latin chars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Entity Embed fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define how record fields will be numericalized and encoded by the neural network. First we set an `alphabet`, here we'll use ASCII numbers, letters, symbols and space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyz!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.data_utils.field_config_parser import DEFAULT_ALPHABET\n",
    "\n",
    "alphabet = DEFAULT_ALPHABET\n",
    "''.join(alphabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's worth noting you can use any alphabet you need, so the accent removal we performed is optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set an `field_config_dict`. It defines `field_type`s that determine how fields are processed in the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_config_dict = {\n",
    "    'number': {\n",
    "        'field_type': \"STRING\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "    'title': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "    'title_semantic': {\n",
    "        'key': 'title',\n",
    "        'field_type': \"SEMANTIC_MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'vocab': \"fasttext.en.300d\",\n",
    "    },\n",
    "    'artist': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "    'album': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "    'album_semantic': {\n",
    "        'key': 'album',\n",
    "        'field_type': \"SEMANTIC_MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'vocab': \"fasttext.en.300d\",\n",
    "    },\n",
    "    'year': {\n",
    "        'field_type': \"STRING\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "    'language': {\n",
    "        'field_type': \"STRING\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use our `field_config_dict` to get a `record_numericalizer`. This object will convert the strings from our records into tensors for the neural network.\n",
    "\n",
    "The same `record_numericalizer` must be used on ALL data: train, valid, test. This ensures numericalization will be consistent. Therefore, we pass `record_list=record_dict.values()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:02:16 INFO:For field=number, computing actual max_str_len\n",
      "09:02:16 INFO:For field=number, using actual_max_str_len=56\n",
      "09:02:16 INFO:For field=title, computing actual max_str_len\n",
      "09:02:16 INFO:For field=title, using actual_max_str_len=38\n",
      "09:02:16 INFO:Downloading vectors from https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec\n",
      ".vector_cache/wiki.en.vec:   1%|          | 46.3M/6.60G [00:10<25:45, 4.24MB/s]    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3d3fa59fffaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mentity_embed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFieldConfigDictParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mrecord_numericalizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFieldConfigDictParser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield_config_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/entity-embed/entity_embed/data_utils/field_config_parser.py\u001b[0m in \u001b[0;36mfrom_dict\u001b[0;34m(cls, field_config_dict, record_list)\u001b[0m\n\u001b[1;32m     53\u001b[0m                         \u001b[0;34mf'\"{found_vocab}\" != \"{current_vocab}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                     )\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mfield_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_field_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mparsed_field_config_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mfield_to_numericalizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_field_numericalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/entity-embed/entity_embed/data_utils/field_config_parser.py\u001b[0m in \u001b[0;36m_parse_field_config\u001b[0;34m(cls, field, field_config, record_list)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 )\n\u001b[1;32m     95\u001b[0m             \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;31m# Compute max_str_len if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/entity-embed/venv/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mload_vectors\u001b[0;34m(self, vectors, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \"vectors are {}\".format(\n\u001b[1;32m    183\u001b[0m                             vector, list(pretrained_aliases.keys())))\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_aliases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 raise ValueError(\n",
      "\u001b[0;32m~/Desktop/entity-embed/venv/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language, **kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFastText\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/entity-embed/venv/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, cache, url, unk_init, max_vectors)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0munk_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munk_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_vectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/entity-embed/venv/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    362\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Extracting vectors into {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/entity-embed/venv/lib/python3.8/site-packages/torchtext/vocab.py\u001b[0m in \u001b[0;36mcache\u001b[0;34m(self, name, cache, url, max_vectors)\u001b[0m\n\u001b[1;32m    359\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'B'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminiters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                             \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreporthook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreporthook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# remove the partial zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1239\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1240\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1241\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1242\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.6/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from entity_embed import FieldConfigDictParser\n",
    "\n",
    "record_numericalizer = FieldConfigDictParser.from_dict(field_config_dict, record_list=record_dict.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under the hood, Entity Embed uses [pytorch-lightning](https://pytorch-lightning.readthedocs.io/en/latest/), so we need to create a datamodule object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed import DeduplicationDataModule\n",
    "\n",
    "batch_size = 32\n",
    "eval_batch_size = 64\n",
    "datamodule = DeduplicationDataModule(\n",
    "    train_record_dict=train_record_dict,\n",
    "    valid_record_dict=valid_record_dict,\n",
    "    test_record_dict=test_record_dict,\n",
    "    cluster_field=cluster_field,\n",
    "    record_numericalizer=record_numericalizer,\n",
    "    batch_size=batch_size,\n",
    "    eval_batch_size=eval_batch_size,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've used `DeduplicationDataModule` because we're doing Deduplication of a single dataset/table (a.k.a. Entity Clustering, Entity Resolution, etc.).\n",
    "\n",
    "We're NOT doing Record Linkage of two datasets here. Check the other notebook [Record-Linkage-Example](Record-Linkage-Example.ipynb) if you want to learn how to do it with Entity Embed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the training process! Thanks to pytorch-lightning, it's easy to train, validate, and test with the same datamodule.\n",
    "\n",
    "We must choose the K of the Approximate Nearest Neighbors, i.e., the top K neighbors our model will use to find duplicates in the embedding space. Below we're setting it on `ann_k` and initializing the `EntityEmbed` model object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed import EntityEmbed\n",
    "\n",
    "ann_k = 100\n",
    "model = EntityEmbed(\n",
    "    record_numericalizer,\n",
    "    ann_k=ann_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train, Entity Embed uses [pytorch-lightning Trainer](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html) on it's `EntityEmbed.fit` method.\n",
    "\n",
    "Since Entity Embed is focused in recall, we'll use `valid_recall_at_0.3` for early stopping. But we'll set `min_epochs = 5` to avoid a very low precision.\n",
    "\n",
    "`0.3` here is the threshold for cosine similarity of embedding vectors, so possible values are between -1 and 1. We're using a validation metric, and the training process will run validation on every epoch end due to `check_val_every_n_epoch=1`.\n",
    "\n",
    "We also set `tb_name` and `tb_save_dir` to use Tensorboard. Run `tensorboard --logdir notebooks/tb_logs` to check the train and valid metrics during and after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trainer = model.fit(\n",
    "    datamodule,\n",
    "    min_epochs=5,\n",
    "    max_epochs=100,\n",
    "    check_val_every_n_epoch=1,\n",
    "    early_stop_monitor=\"valid_recall_at_0.3\",\n",
    "    tb_save_dir='tb_logs',\n",
    "    tb_name='music',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EntityEmbed.fit` keeps only the weights of the best validation model. With them, we can check the best performance on validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.validate(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can check which fields are most important for the final embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_pool_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again with the best validation model, we can check the performance on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.test(datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing manually (like a production run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running in production, you only have access to the trained `model` object and the production `record_dict` (without the `cluster_field` filled, of course).\n",
    "\n",
    "So let's simulate that by removing `cluster_field` from the test_record_dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "test_record_dict_with_cluster = datamodule.test_record_dict\n",
    "test_record_dict = copy.deepcopy(test_record_dict_with_cluster)\n",
    "\n",
    "for record in test_record_dict.values():\n",
    "    del record[cluster_field]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep the `test_pos_pair_set` in a variable for evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_pair_set = datamodule.test_pos_pair_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vector_dict = model.predict(\n",
    "    record_dict=test_record_dict,\n",
    "    batch_size=eval_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-check if returned embeddings on `test_vector_dict` have the same length of `test_record_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(test_vector_dict) == len(test_record_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now init an `ANNEntityIndex`, insert all embeddings from `test_vector_dict` on it, and build it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from entity_embed import ANNEntityIndex\n",
    "\n",
    "ann_index = ANNEntityIndex(embedding_size=model.embedding_size)\n",
    "ann_index.insert_vector_dict(test_vector_dict)\n",
    "ann_index.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the index built, we can now search on it and find the candidate duplicate pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sim_threshold = 0.3\n",
    "found_pair_set = ann_index.search_pairs(\n",
    "    k=ann_k,\n",
    "    sim_threshold=sim_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check now the metrics of the found duplicate pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import pair_entity_ratio\n",
    "\n",
    "pair_entity_ratio(len(found_pair_set), len(test_record_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import precision_and_recall\n",
    "\n",
    "precision_and_recall(found_pair_set, test_pos_pair_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same numbers of the `trainer.test`, so our manual testing is fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can check the false positives and negatives to see if they're really difficult:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = list(found_pair_set - test_pos_pair_set)\n",
    "len(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = list(test_pos_pair_set - found_pair_set)\n",
    "len(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = lambda a, b: np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (id_left, id_right) in false_positives[:3]:\n",
    "    display(\n",
    "        (\n",
    "            cos_similarity(test_vector_dict[id_left], test_vector_dict[id_right]),\n",
    "            utils.subdict(record_dict[id_left], field_list), utils.subdict(record_dict[id_right], field_list)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (id_left, id_right) in false_negatives[:3]:\n",
    "    display(\n",
    "        (\n",
    "            cos_similarity(test_vector_dict[id_left], test_vector_dict[id_right]),\n",
    "            utils.subdict(record_dict[id_left], field_list), utils.subdict(record_dict[id_right], field_list)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-sne visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a small sample of the test embeddings and see if they look properly clustered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster_dict = utils.record_dict_to_cluster_dict(test_record_dict_with_cluster, cluster_field)\n",
    "vis_cluster_dict = dict(sorted(test_cluster_dict.items(), key=lambda x: len(x[1]), reverse=True)[:vis_sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_x = np.stack([test_vector_dict[id_] for cluster in vis_cluster_dict.values() for id_ in cluster])\n",
    "vis_y = np.array([cluster_id for cluster_id, cluster in vis_cluster_dict.items() for __ in cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tnse = TSNE(metric='cosine', perplexity=20, random_state=random_seed)\n",
    "tsne_results = tnse.fit_transform(vis_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.scatterplot(\n",
    "    x=tsne_results[:,0],\n",
    "    y=tsne_results[:,1],\n",
    "    hue=vis_y,\n",
    "    palette=sns.color_palette(\"hls\", len(vis_cluster_dict.keys())),\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")\n",
    "for id_, (x, y) in zip(itertools.chain.from_iterable(vis_cluster_dict.values()), tsne_results):\n",
    "    # text = id_\n",
    "    text = test_record_dict[id_]['title'][:30]\n",
    "    ax.text(x + 2, y + 2, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
