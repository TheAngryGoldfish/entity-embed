{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libgomp issue, must import n2 before torch\n",
    "from n2 import HnswIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "home_dir = os.getenv('HOME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dbs.uni-leipzig.de/research/projects/object_matching/benchmark_datasets_for_entity_resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b567ba8927846ea9136ee1be6ab65d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4589.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import csv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from entity_embed.data_utils.utils import Enumerator\n",
    "\n",
    "id_enumerator = Enumerator()\n",
    "row_dict = {}\n",
    "left_id_set = set()\n",
    "right_id_set = set()\n",
    "rows_total = 1363 + 3226\n",
    "clusters_total = 1300\n",
    "\n",
    "with tqdm(total=rows_total) as pbar:\n",
    "    with open(f'{home_dir}/Downloads/Amazon-GoogleProducts/Amazon.csv', encoding=\"latin1\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            row['id'] = id_enumerator[row[\"id\"]]\n",
    "            row['name'] = row.pop('title')\n",
    "            row['source'] = 'google'\n",
    "            row_dict[row['id']] = row\n",
    "            left_id_set.add(row['id'])\n",
    "            pbar.update(1)\n",
    "    \n",
    "    with open(f'{home_dir}/Downloads/Amazon-GoogleProducts/GoogleProducts.csv', encoding=\"latin1\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            row['id'] = id_enumerator[row[\"id\"]]\n",
    "            row['source'] = 'amazon'\n",
    "            row_dict[row['id']] = row\n",
    "            right_id_set.add(row['id'])\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_pair_set = set()\n",
    "\n",
    "with open(f'{home_dir}/Downloads/Amazon-GoogleProducts/Amzon_GoogleProducts_perfectMapping.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        id_left = id_enumerator[row['idAmazon']]\n",
    "        id_right = id_enumerator[row['idGoogleBase']]\n",
    "        true_pair_set.add((id_left, id_right))\n",
    "\n",
    "len(true_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2404"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.data_utils.utils import id_pairs_to_cluster_mapping_and_dict\n",
    "\n",
    "cluster_mapping, cluster_dict = id_pairs_to_cluster_mapping_and_dict(true_pair_set)\n",
    "len(cluster_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: deal with this difference\n",
    "# from entity_embed.data_utils.utils import cluster_dict_to_id_pairs\n",
    "\n",
    "# assert len(true_pair_set - cluster_dict_to_id_pairs(cluster_dict)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e227ecda48e4d0a9aa967409a706119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4589.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cluster_attr = 'cluster_id'\n",
    "max_cluster_id = max(cluster_mapping.values())\n",
    "\n",
    "for row_id, row in tqdm(row_dict.items()):\n",
    "    try:\n",
    "        row[cluster_attr] = cluster_mapping[row_id]\n",
    "    except KeyError:\n",
    "        row[cluster_attr] = max_cluster_id\n",
    "        max_cluster_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 938,\n",
       "  'description': 'improve your typing skills today! typing instructor deluxe has a progressive design that has been developed for over 19 years. typing instructor deluxe can provide the right lessons tests strengthening exercises practice material and typing games for your skill level. you can even build your own personal typing plan to focus on specific areas you would like to improve. if you think learning has to be all hard work and no fun think again! for beginning to advanced typists kids to adults typing instructor deluxe will motivate you to improve your typing speed and accuracy using a travel theme and exciting typing challenges.educates entertains and motivates: choose from many typing plans or build your ownnavigate easily and choose your typing materialnew! dynamic learning methodsave your results and reports to track progresslearn voice-touch typing (dictation)3 unique travel themescolorful photos and musicten exciting games300+ magazine articles',\n",
       "  'manufacturer': 'individual software',\n",
       "  'price': '9.99',\n",
       "  'name': 'typing instructor deluxe (jewel case)',\n",
       "  'source': 'google',\n",
       "  'cluster_id': 938},\n",
       " {'id': 2238,\n",
       "  'name': 'individual software inc typing instructor deluxe j/c',\n",
       "  'description': 'for all ages typing instructor deluxe is targeted to pc users at every level who want to learn how to touch type. incluees 3 travel themes dynamic typing tests new multi-level games and custom personalization. system requiremen',\n",
       "  'manufacturer': '',\n",
       "  'price': '6.84',\n",
       "  'source': 'amazon',\n",
       "  'cluster_id': 938}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[row_dict[row_id] for row_id in next(iter(true_pair_set))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_list = ['name', 'description', 'manufacturer', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79387073001b4bdb81b51ef4fa703c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4589.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import itertools\n",
    "from entity_embed import default_tokenizer\n",
    "\n",
    "def clean_str(s):\n",
    "    s = unidecode.unidecode(s).lower().strip()\n",
    "    s_tokens = itertools.islice((s_part[:30] for s_part in default_tokenizer(s)), 0, 30)\n",
    "    return ' '.join(s_tokens)[:300]\n",
    "\n",
    "for row in tqdm(row_dict.values()):\n",
    "    for attr in attr_list:\n",
    "        row[attr] = clean_str(row[attr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = list('0123456789abcdefghijklmnopqrstuvwxyz!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_info_dict = {\n",
    "    'name': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "        'use_mask': True,\n",
    "    },\n",
    "    'description': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "        'use_mask': True,\n",
    "    },\n",
    "    'manufacturer': {\n",
    "        'field_type': \"MULTITOKEN\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "        'use_mask': True,\n",
    "    },\n",
    "    'price': {\n",
    "        'field_type': \"STRING\",\n",
    "        'tokenizer': \"entity_embed.default_tokenizer\",\n",
    "        'alphabet': alphabet,\n",
    "        'max_str_len': None,  # compute\n",
    "        'use_mask': True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:59:46 INFO:For attr='name', computing actual max_str_len\n",
      "16:59:46 INFO:For attr='name', using actual_max_str_len=26\n",
      "16:59:46 INFO:For attr='description', computing actual max_str_len\n",
      "16:59:46 INFO:actual_max_str_len=29 must be pair to enable NN pooling. Updating to 30\n",
      "16:59:46 INFO:For attr='description', using actual_max_str_len=30\n",
      "16:59:46 INFO:For attr='manufacturer', computing actual max_str_len\n",
      "16:59:46 INFO:actual_max_str_len=15 must be pair to enable NN pooling. Updating to 16\n",
      "16:59:46 INFO:For attr='manufacturer', using actual_max_str_len=16\n",
      "16:59:46 INFO:For attr='price', computing actual max_str_len\n",
      "16:59:46 INFO:For attr='price', using actual_max_str_len=14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': NumericalizeInfo(field_type=<FieldType.MULTITOKEN: 'multitoken'>, tokenizer=<function default_tokenizer at 0x7f21bc88ad30>, alphabet=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' '], max_str_len=26, vocab=None, n_channels=8, embed_dropout_p=0.2, use_attention=True, use_mask=False),\n",
       " 'description': NumericalizeInfo(field_type=<FieldType.MULTITOKEN: 'multitoken'>, tokenizer=<function default_tokenizer at 0x7f21bc88ad30>, alphabet=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' '], max_str_len=30, vocab=None, n_channels=8, embed_dropout_p=0.2, use_attention=True, use_mask=False),\n",
       " 'manufacturer': NumericalizeInfo(field_type=<FieldType.MULTITOKEN: 'multitoken'>, tokenizer=<function default_tokenizer at 0x7f21bc88ad30>, alphabet=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' '], max_str_len=16, vocab=None, n_channels=8, embed_dropout_p=0.2, use_attention=True, use_mask=False),\n",
       " 'price': NumericalizeInfo(field_type=<FieldType.STRING: 'string'>, tokenizer=<function default_tokenizer at 0x7f21bc88ad30>, alphabet=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' '], max_str_len=14, vocab=None, n_channels=8, embed_dropout_p=0.2, use_attention=True, use_mask=False)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from entity_embed.data_utils.helpers import AttrInfoDictParser\n",
    "\n",
    "row_numericalizer = AttrInfoDictParser.from_dict(attr_info_dict, row_dict=row_dict)\n",
    "row_numericalizer.attr_info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed import LinkageDataModule\n",
    "\n",
    "train_cluster_len = 200\n",
    "valid_cluster_len = 200\n",
    "datamodule = LinkageDataModule(\n",
    "    row_dict=row_dict,\n",
    "    cluster_attr=cluster_attr,\n",
    "    row_numericalizer=row_numericalizer,\n",
    "    pos_pair_batch_size=45,\n",
    "    neg_pair_batch_size=1225,\n",
    "    row_batch_size=16,\n",
    "    train_cluster_len=train_cluster_len,\n",
    "    valid_cluster_len=valid_cluster_len,\n",
    "    test_cluster_len=clusters_total - valid_cluster_len - train_cluster_len,\n",
    "    only_plural_clusters=True,\n",
    "    left_id_set=left_id_set,\n",
    "    right_id_set=right_id_set,\n",
    "    random_seed=random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'use_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c4306e496b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mann_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model = LinkageEmbed(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mann_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mann_k\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'use_mask'"
     ]
    }
   ],
   "source": [
    "from entity_embed import LinkageEmbed\n",
    "\n",
    "ann_k = 100\n",
    "model = LinkageEmbed(\n",
    "    datamodule,\n",
    "    ann_k=ann_k,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "max_epochs = 50\n",
    "early_stop_callback = EarlyStopping(\n",
    "   monitor='valid_recall_at_0.3',\n",
    "   min_delta=0.00,\n",
    "   patience=10,\n",
    "   verbose=True,\n",
    "   mode='max'\n",
    ")\n",
    "tb_log_dir = 'tb_logs'\n",
    "tb_name = 'amzn-googl'\n",
    "trainer = pl.Trainer(\n",
    "    gpus=1,\n",
    "    max_epochs=max_epochs,\n",
    "    check_val_every_n_epoch=1,\n",
    "    callbacks=[early_stop_callback],\n",
    "    logger=TensorBoardLogger(tb_log_dir, name=tb_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocker_net.get_signature_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(ckpt_path='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing manually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only call this if test above wasn't run\n",
    "# datamodule.setup(stage='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row_dict = datamodule.test_row_dict\n",
    "test_left_vector_dict, test_right_vector_dict = model.predict(\n",
    "    row_dict=test_row_dict,\n",
    "    left_id_set=left_id_set,\n",
    "    right_id_set=right_id_set,\n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = model.blocker_net.embedding_size\n",
    "test_true_pair_set = datamodule.test_true_pair_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (len(test_left_vector_dict) + len(test_right_vector_dict)) == len(test_row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from entity_embed import ANNLinkageIndex\n",
    "\n",
    "ann_index = ANNLinkageIndex(embedding_size=embedding_size)\n",
    "ann_index.insert_vector_dict(left_vector_dict=test_left_vector_dict, right_vector_dict=test_right_vector_dict)\n",
    "ann_index.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sim_threshold = 0.3\n",
    "found_pair_set = ann_index.search_pairs(\n",
    "    k=ann_k,\n",
    "    sim_threshold=sim_threshold,\n",
    "    left_vector_dict=test_left_vector_dict,\n",
    "    right_vector_dict=test_right_vector_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import pair_entity_ratio\n",
    "\n",
    "pair_entity_ratio(len(found_pair_set), len(test_row_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.evaluation import precision_and_recall\n",
    "\n",
    "precision_and_recall(found_pair_set, test_true_pair_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = list(found_pair_set - test_true_pair_set)\n",
    "len(false_positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = list(test_true_pair_set - found_pair_set)\n",
    "len(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_similarity = lambda a, b: np.dot(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (id_left, id_right) in false_negatives[:10]:\n",
    "    display(\n",
    "        (\n",
    "            cos_similarity(test_left_vector_dict[id_left], test_right_vector_dict[id_right]),\n",
    "            row_dict[id_left], row_dict[id_right]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-sne visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_sample_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from entity_embed.data_utils.utils import row_dict_to_cluster_dict\n",
    "\n",
    "test_vector_dict = {**test_left_vector_dict, **test_right_vector_dict}\n",
    "test_cluster_dict = row_dict_to_cluster_dict(test_row_dict, cluster_attr)\n",
    "vis_cluster_dict = dict(sorted(test_cluster_dict.items(), key=lambda x: len(x[1]), reverse=True)[:vis_sample_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_x = np.stack([test_vector_dict[id_] for cluster in vis_cluster_dict.values() for id_ in cluster])\n",
    "vis_y = np.array([cluster_id for cluster_id, cluster in vis_cluster_dict.items() for __ in cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tnse = TSNE(metric='cosine', perplexity=10, random_state=random_seed)\n",
    "tsne_results = tnse.fit_transform(vis_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax = sns.scatterplot(\n",
    "    x=tsne_results[:,0],\n",
    "    y=tsne_results[:,1],\n",
    "    hue=vis_y,\n",
    "    palette=sns.color_palette(\"hls\", len(vis_cluster_dict.keys())),\n",
    "    legend=\"full\",\n",
    "    alpha=0.8\n",
    ")\n",
    "for id_, (x, y) in zip(itertools.chain.from_iterable(vis_cluster_dict.values()), tsne_results):\n",
    "    # text = id_\n",
    "    text = test_row_dict[id_]['name'][:30]\n",
    "    ax.text(x + 2, y + 2, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
